{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import pandas as pd\n","import torch\n","from torch.utils.data import Dataset, random_split\n","from transformers import GPT2Tokenizer, TrainingArguments, Trainer, GPT2LMHeadModel"]},{"cell_type":"code","execution_count":2,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Thu May  5 20:11:23 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 512.15       Driver Version: 512.15       CUDA Version: 11.6     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  NVIDIA GeForce ... WDDM  | 00000000:2B:00.0  On |                  N/A |\n","|  0%   55C    P8     6W / 170W |    517MiB / 12288MiB |     10%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|    0   N/A  N/A       736    C+G   ...t\\Teams\\current\\Teams.exe    N/A      |\n","|    0   N/A  N/A      2172    C+G   ...ekyb3d8bbwe\\YourPhone.exe    N/A      |\n","|    0   N/A  N/A      4288    C+G   ...ekyb3d8bbwe\\onenoteim.exe    N/A      |\n","|    0   N/A  N/A      9520    C+G   ...\\app-1.0.9004\\Discord.exe    N/A      |\n","|    0   N/A  N/A     10192    C+G   ...artMenuExperienceHost.exe    N/A      |\n","|    0   N/A  N/A     10748    C+G   ...2txyewy\\TextInputHost.exe    N/A      |\n","|    0   N/A  N/A     13424    C+G   ...t\\Teams\\current\\Teams.exe    N/A      |\n","|    0   N/A  N/A     14436    C+G                                   N/A      |\n","|    0   N/A  N/A     15208    C+G   ...n1h2txyewy\\SearchHost.exe    N/A      |\n","|    0   N/A  N/A     15700    C+G   ...icrosoft VS Code\\Code.exe    N/A      |\n","|    0   N/A  N/A     15916    C+G   C:\\Windows\\explorer.exe         N/A      |\n","|    0   N/A  N/A     17512    C+G   ...lPanel\\SystemSettings.exe    N/A      |\n","|    0   N/A  N/A     20376    C+G   ...210.32\\msedgewebview2.exe    N/A      |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":3,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["<torch._C.Generator at 0x21fe7cf9af0>"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["torch.manual_seed(50)"]},{"cell_type":"markdown","metadata":{},"source":["### Loading GPT2-Medium Model from ðŸ¤— Model Hub "]},{"cell_type":"code","execution_count":4,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"data":{"text/plain":["Embedding(50259, 1024)"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["\n","\n","tokenizer = GPT2Tokenizer.from_pretrained('indonesian-nlp/gpt2-medium-indonesian', bos_token='<|startoftext|>',\n","                                          eos_token='<|endoftext|>', pad_token='<|pad|>')\n","model = GPT2LMHeadModel.from_pretrained('indonesian-nlp/gpt2-medium-indonesian').cuda()\n","model.resize_token_embeddings(len(tokenizer))\n"]},{"cell_type":"code","execution_count":5,"metadata":{"trusted":true},"outputs":[],"source":["captions = pd.read_csv('list_caption.csv')['processed']"]},{"cell_type":"code","execution_count":6,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]}],"source":["max_length = max([len(tokenizer.encode(caption, max_length=512)) for caption in captions])"]},{"cell_type":"code","execution_count":7,"metadata":{"trusted":true},"outputs":[],"source":["class CaptionDataset(Dataset):\n","    def __init__(self, txt_list, tokenizer, max_length):\n","        self.input_ids = []\n","        self.attn_masks = []\n","        self.labels = []\n","        for txt in txt_list:\n","            encodings_dict = tokenizer('<|startoftext|>' + txt + '<|endoftext|>', truncation=True,\n","                                       max_length=max_length, padding=\"max_length\")\n","            self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n","            self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n","\n","    def __len__(self):\n","        return len(self.input_ids)\n","\n","    def __getitem__(self, idx):\n","        return self.input_ids[idx], self.attn_masks[idx]"]},{"cell_type":"code","execution_count":8,"metadata":{"trusted":true},"outputs":[],"source":["dataset = CaptionDataset(captions, tokenizer, max_length=max_length)\n","train_size = int(0.9 * len(dataset))\n","train_dataset, val_dataset = random_split(dataset, [train_size, len(dataset) - train_size])\n"]},{"cell_type":"code","execution_count":9,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["13"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["import gc\n","gc.collect()"]},{"cell_type":"code","execution_count":10,"metadata":{"trusted":true},"outputs":[],"source":["torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":11,"metadata":{"trusted":true},"outputs":[],"source":["training_args = TrainingArguments(output_dir='./results', num_train_epochs=3, logging_steps=100, save_steps=5000,\n","                                  per_device_train_batch_size=1, per_device_eval_batch_size=1,\n","                                  warmup_steps=10, weight_decay=0.05, logging_dir='./logs', report_to = 'none', fp16=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["Trainer(model=model,  args=training_args, train_dataset=train_dataset, \n","        eval_dataset=val_dataset, data_collator=lambda data: {'input_ids': torch.stack([f[0] for f in data]),\n","                                                              'attention_mask': torch.stack([f[1] for f in data]),\n","                                                              'labels': torch.stack([f[0] for f in data])}).train()"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Configuration saved in ./results\\config.json\n","Model weights saved in ./results\\pytorch_model.bin\n"]}],"source":["#save model\n","model.save_pretrained('./results')"]},{"cell_type":"markdown","metadata":{},"source":["### OA Line Caption Generator"]},{"cell_type":"code","execution_count":282,"metadata":{"trusted":true},"outputs":[],"source":["generated = tokenizer(\"<|startoftext|> Informasi Menggelitik\", return_tensors=\"pt\").input_ids.cuda()"]},{"cell_type":"code","execution_count":283,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]}],"source":["sample_outputs = model.generate(generated, do_sample=True, top_k=50, \n","                                max_length=512, top_p=1.5, temperature=0.8)\n"]},{"cell_type":"code","execution_count":284,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":[" Informasi Menggelitik  - \"Ya ampun, sekarang udah mau kuliah lagi aja!\" -nya, salah satu anggota dari BSO Minat dan Bakat HIMAGIKA yang bertugas untuk mengoordinasi minat dan bakat di dalam dan di luar bidang gizi kesehatan FK UGM. \n","Bironya anak Gizi Kesehatan, tapi yang ngatur anak-anak Gizi UTS ya kan?? \n","Eh, bukan..... Bironya anak-anak yang hobi baca, kalo kalian suka baca apa? \n","Kalo kalian suka baca apa nih?\n","-Sastra-\n","\n","\n","\n","\n","\n","\n","\n","FIND MORE!\n","Email : himagika@ugm.ac.id\n","\n","\n","Website : himagika.fk.ugm.ac.id\n","Tiktok : @himagika.ugm\n","LINE@ : @clw3634c\n","\n","\n","\n","\n"]}],"source":["for i, sample_output in enumerate(sample_outputs):\n","    print(tokenizer.decode(sample_output, skip_special_tokens=True))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":4}
